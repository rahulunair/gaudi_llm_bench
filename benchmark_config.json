# https://www.intel.com/content/www/us/en/developer/platform/gaudi/model-performance-gaudi2-inference.html
{
    "models": [
        {
            "name": "llama3.2-11b-vision",
            "model_id": "meta-llama/Llama-3.2-11B-Vision",
            "size": 11,
            "cards_required": 1,
            "configs": [
                {"input_tokens": 128, "output_tokens": 128, "batch_size": 2816},
                {"input_tokens": 128, "output_tokens": 2048, "batch_size": 512},
                {"input_tokens": 2048, "output_tokens": 128, "batch_size": 179},
                {"input_tokens": 2048, "output_tokens": 2048, "batch_size": 256}
            ]
        },
        {
            "name": "llama3.2-90b-vision",
            "model_id": "meta-llama/Llama-3.2-90B-Vision",
            "size": 90,
            "cards_required": 8,
            "configs": [
                {"input_tokens": 128, "output_tokens": 128, "batch_size": 1792},
                {"input_tokens": 128, "output_tokens": 2048, "batch_size": 256},
                {"input_tokens": 2048, "output_tokens": 128, "batch_size": 142},
                {"input_tokens": 2048, "output_tokens": 2048, "batch_size": 139}
            ]
        }
    ],
    "output_dir": "benchmark_results"
}
